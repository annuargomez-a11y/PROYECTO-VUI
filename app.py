import os
import sys
import logging
import streamlit as st
import nest_asyncio
from datetime import datetime

# --- 1. PARCHES DE SISTEMA ---
nest_asyncio.apply()
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
    Settings,
    PromptTemplate
)
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

# --- 2. CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(
    page_title="Asistente Janus (VUI)",
    page_icon="üóùÔ∏è",
    layout="centered"
)

# --- 3. API KEYS ---
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    st.error("Error Cr√≠tico: Falta la clave API de OpenAI en los Secrets.")
    st.stop()

pdf_folder_path = "./ARCHIVOS/"
persist_dir = "./storage"

# --- 4. MOTOR RAG ---
@st.cache_resource
def get_query_engine():
    
    # Cerebro (GPT-4o-mini)
    llm = OpenAI(model="gpt-4o-mini", temperature=0)
    embed_model = OpenAIEmbedding(model="text-embedding-3-large")

    Settings.llm = llm
    Settings.embed_model = embed_model
    
    # Carga
    reader = SimpleDirectoryReader(input_dir=pdf_folder_path, recursive=True)
    documents = reader.load_data()
    
    node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=100)
    nodes = node_parser.get_nodes_from_documents(documents)
    
    index = VectorStoreIndex(nodes, show_progress=True)
    
    # Template enfocado en CONTENIDO (No nos preocupamos por el idioma aqu√≠)
    # Dejamos que responda en su idioma natural (Espa√±ol) para asegurar precisi√≥n t√©cnica.
    template_str = (
        "Eres Janus, el Asistente Oficial de la VUI Colombia.\n"
        "Rol: FACILITADOR ESTRAT√âGICO.\n"
        "---------------------\n"
        "Contexto:\n{context_str}\n"
        "---------------------\n"
        "Instrucciones:\n"
        "1. REGLA VUE: Para crear empresas, refiere a VUE (Ventanilla √önica Empresarial), NO VUCE.\n"
        "2. CONTENIDO: Prioriza pasos pr√°cticos ('C√ìMO').\n"
        "3. FORMATO: Usa Markdown (negritas, listas).\n"
        "Pregunta: {query_str}\n"
        "Respuesta (en Espa√±ol):"
    )
    
    qa_template = PromptTemplate(template_str)
    
    query_engine = index.as_query_engine(
        similarity_top_k=5,
        text_qa_template=qa_template
    ) 
    return query_engine

# --- 5. FUNCI√ìN DE TRADUCCI√ìN (LA SOLUCI√ìN DEFINITIVA) ---
def translate_response(original_response, user_query):
    """
    Toma la respuesta (que seguramente est√° en Espa√±ol) y la traduce 
    al idioma de la pregunta del usuario usando una llamada pura al LLM.
    """
    # Si la pregunta ya est√° en espa√±ol, no gastamos tiempo traduciendo
    # (Esta es una detecci√≥n simple, el LLM lo har√° mejor)
    
    client = OpenAI(model="gpt-4o-mini", temperature=0)
    
    prompt_traduccion = (
        f"User Query: '{user_query}'\n"
        f"Original Answer: '{original_response}'\n\n"
        "TASK: Analyze the language of the 'User Query'. "
        "Translate the 'Original Answer' into that EXACT same language. "
        "Maintain all Markdown formatting (bolding, lists). "
        "If the query is already in Spanish, just return the Original Answer as is.\n"
        "Translated Answer:"
    )
    
    return client.complete(prompt_traduccion).text

# --- 6. INTERFAZ DE USUARIO ---
st.title("Asistente Janus")
st.caption("Tu gu√≠a para la Ventanilla √önica de Inversi√≥n (VUI).")

tab_chat, tab_faq = st.tabs(["Consultar a Janus üí¨", "Preguntas Frecuentes üí°"])

try:
    query_engine = get_query_engine()
except Exception as e:
    st.error(f"Error al cargar el motor: {e}")
    st.stop()

# --- Pesta√±a 1: Chat ---
with tab_chat:
    st.header("Haz tu consulta")
    st.markdown("¬°Hola! Soy Janus. Estoy aqu√≠ para guiarte en tu Inversi√≥n Directa en Colombia.")

    with st.form("query_form"):
        prompt = st.text_area("Escribe tu consulta aqu√≠ (Cualquier idioma):", height=100)
        submitted = st.form_submit_button("Enviar Consulta a Janus")

    if submitted and prompt:
        with st.spinner("Janus est√° analizando y traduciendo..."):
            try:
                # 1. Obtener respuesta t√©cnica (En Espa√±ol)
                respuesta_raw = query_engine.query(prompt)
                
                # 2. Traducir al idioma del usuario (El paso que asegura el ingl√©s)
                response_text = translate_response(str(respuesta_raw), prompt)
                
                with st.expander("Ver Respuesta de Janus", expanded=True):
                    st.markdown(response_text)
                    
                    # Descarga
                    ahora = datetime.now()
                    nombre = f"Janus.Answer.{ahora.strftime('%Y%m%d.%H%M')}.txt"
                    contenido = f"PREGUNTA:\n{prompt}\n\nRESPUESTA:\n{response_text}"
                    
                    st.download_button("üì• Guardar Respuesta (TXT)", data=contenido, file_name=nombre, mime="text/plain")
            except Exception as e:
                st.error(f"Error: {e}")

# --- Pesta√±a 2: FAQs ---
with tab_faq:
    st.header("Preguntas Frecuentes")
    
    faq_1 = "¬øQu√© incentivos fiscales hay para energ√≠as renovables no convencionales?"
    faq_2 = "¬øCu√°l es la estructura de sociedad recomendada (S.A.S.) y capital m√≠nimo?"
    faq_3 = "¬øExisten restricciones para repatriar utilidades al exterior?"
    
    def run_faq(question):
        with st.spinner("Consultando..."):
            resp = query_engine.query(question)
            txt_resp = str(resp) # Las FAQs est√°n en espa√±ol, as√≠ que no necesitan traducci√≥n
            with st.expander("Respuesta", expanded=True):
                st.markdown(txt_resp)
                st.download_button("üì• Descargar TXT", data=f"P:{question}\nR:{txt_resp}", file_name="FAQ.txt")

    if st.button(faq_1): run_faq(faq_1)
    if st.button(faq_2): run_faq(faq_2)
    if st.button(faq_3): run_faq(faq_3)
